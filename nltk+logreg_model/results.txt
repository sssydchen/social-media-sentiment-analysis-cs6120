NLTK Model Evaluation (CountVectorizer + NB):
              precision    recall  f1-score   support

    negative       0.80      0.95      0.87      1889
     neutral       0.68      0.40      0.50       580
    positive       0.81      0.61      0.70       459

    accuracy                           0.79      2928
   macro avg       0.76      0.65      0.69      2928
weighted avg       0.78      0.79      0.77      2928

Logistic Regression Model Evaluation (TF-IDF + N-gram):

              precision    recall  f1-score   support

    negative       0.82      0.94      0.88      1889
     neutral       0.69      0.47      0.56       580
    positive       0.81      0.63      0.71       459

    accuracy                           0.80      2928
   macro avg       0.77      0.68      0.71      2928
weighted avg       0.79      0.80      0.79      2928

TensorFlow Evaluation:

              precision    recall  f1-score   support

    negative       0.89      0.82      0.85      1835
     neutral       0.58      0.67      0.62       620
    positive       0.67      0.74      0.70       473

    accuracy                           0.77      2928
   macro avg       0.71      0.74      0.73      2928
weighted avg       0.79      0.77      0.78      2928

Bert Evaluation:

              precision    recall  f1-score   support

    negative       0.90      0.92      0.91      1825
     neutral       0.75      0.67      0.71       638
    positive       0.79      0.83      0.81       465

    accuracy                           0.85      2928
   macro avg       0.81      0.81      0.81      2928
weighted avg       0.85      0.85      0.85      2928